# TIL(Today I Learned)

___

> Fab/14th/2022_Multi campus_유선종 Day34

## 머신러닝
오늘부터 머신러닝에 대해 학습을 시작한다. 머신러닝은 이론적인 부분도 많이 포함되어 있기 때문에 이론에 대한 부분과 코딩에 대한 부분을 적절히 섞어가면서 머신러닝에 대해 알아보고자 한다.

### 1. What is machine Learning
머신러닝의 정의는 컴퓨터 시스템에 명시적으로 프로그래밍을 하지 않아도 데이터를 스스로 학습하여 문제를 해결할 수 있게 하는 기술을 의미한다. 즉, 머신러닝을 하기 위한 기본적인 전제 조건은 컴퓨터의 계산과 데이터, 그리고 그 데이터를 학습하여 결과를 내기 위한 모델이 필수적이다.

1. 컴퓨터의 계산 능력은 수많은 데이터를 계산하기 위해 필수적이다. 어느순간 컴퓨터의 성능이 발전함에 따라 인간의 계산 능력보다 월등히 뛰어나게 발전하였고, 이제는 우리가 이해하지 못하는 영역까지 도달했다. 수억개의 변수들을 계산하는데 과연 우리가 그것을 계산할 능력이 있는가? 단언컨데 없다. 하지만 컴퓨터가 있기 때문에 우리는 인간의 영역을 뛰어넘는 계산이 가능해졌다.
2. 아무리 뛰어난 계산능력이더라도 계산할 대상이 존재하지 않는다면 아무런 쓸모가 없다. 머리는 좋은데 든게 없으면 무슨 소용이 있겠는가? 하지만 우리는 이미 컴퓨터가 나오고 스마트폰이 나오면서 수많은 데이터가 축적되었다. 이제 머신러닝을 할 수 있는 조건이 마련이 됐다.
3. 마지막으로 이러한 데이터들간의 관계를 뽑아서 우리가 예측을 하거나 어떤 의미를 뽑아내기 위해 데이터를 계산하는 방법이 필요하다. 그 방법론이 바로 모델이다. 우리는 적잘한 모델을 선택하고 평가하여 의미를 뽑아내는 것은 인간이 해야하는 영역이다. ~물론 최근에는 이러한 영역도 컴퓨터가 담당하기 시작했다.~

___
### 2. 머신러닝의 종류
머신러닝의 종류는 크게 4가지로 구성되어 있는데, 지도학습(Supervised Learning), 비지도학습(Unsuperviesd Learning), 준지도학습(Semi-supervised Learning), 강화학습(Reinforcement Learning)으로 구성되어 있다.

#### 1. 지도학습(Supervised Learning)
- 지도학습은 어떠한 규칙을 부여하는 등의 감독(supervied)하는 역할이 있는 학습(Learning)방식을 말한다. 여기서 감독을 하는 역할은 사람이 할 것이다.
- 어떤 정답 묶음(Label)을 설정해서 이 정답과 가장 유사한 결과를 도출하는 알고리즘(Algorism)을 선택하여 이러한 알고리즘을 바탕으로 실제 데이터를 넣어 모델을 만든다.
- 여러 종류의 지도학습 방식이 있는데 대표적인 것이 회귀분석(Regression)과 분류분석(Classification)이다. 회귀분석은 어떠한 답이 정해져있는 모수를 추정을 통해 직선의 형태로 도출하는 것이고, 분류분석은 데이터를 분류하는 직선을 구하는 분석이다. 
- 맨밑에서 지도학습 중에서 분류분석의 예제를 통해 간단히 학습해보자.

### 2. 비지도학습(Unsupervised Learning)
- 비지도학습은 지도학습과는 반대로 어떠한 알고리즘이나 규칙성 없이 오직 데이터 안에서 규칙을 찾아내는 방법이다. 즉, 엄청나게 많은 데이터들을 학습해서 그 안의 규칙성이나 반복되는 패턴 등을 발견해내서 의미를 도출해내는 방법이다.
- 크게 군집분석(Clusterring), 연관분석(Association), 차원축소(Dimensionality Reduction) 등이 있다. 군집분석은 데이터를 그룹화하는 것이고, 연관분석은 데이터들의 상관관계를 도출하며, 차원축소은 너무나 많은 독립변수를 데이터가 가지고 있는 규칙성을 최대한 훼손하지 않고 변수들을 줄이는 방법이다.

### 3. 준지도학습(Semi-supervised Learning)
- 준지도학습은 위의 지도학습과 비지도학습을 적절히 섞어서 사용하는 방식이다.

### 4. 강화학습(Reinforcement Learning)
- 강화학습은 보상을 통해 어떠한 결과를 더욱 강화시키는 방법이다.
- 기본적으로 비지도학습을 통해 규칙성을 발견하고 학습을 하게 되고, 어떠한 결과가 도출될텐데 이때, 인공지능이 선택한 결과에 대해 각기 다른 보상을 주는 방식이다. 만약, 최적의 선택을 찾았을 경우 보상을 크게 준다면, 인공지능은 그 보상을 가장 크게 만드는 최적의 방식을 찾아 학습을 할 것이다.

___

### 3. 지도학습 예시
다음은 지도학습의 간단한 예시를 보겠다. 여기서 중요한 것은 전체 데이터 모음 중에서 약 20%는 테스트용 데이터, 나머지 80%는 훈련용 데이터로 분류한다는 것이다. 그 이유는 훈련용 데이터로 모델을 학습하고 그 학습한 모델이 정말 데이터를 잘 설명하는 모델인지 확인하기 위해 테스트용 데이터를 모델에 넣어서 확인해본다. 자세한 내용을 천천히 살펴보자.

#### 1. 데이터셋
```python
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

length = bream_length + smelt_length
weight = bream_weight + smelt_weight
```
1. 데이터 시각화를 위한 matplotlib과 행렬연산을 위한 numpy, 그리고 머신러닝 라이브러리인 scikit-learn(sklearn)을 불러온다.
2. bream은 도미, smelt는 빙어를 의미한다. 즉, 빙어와 도미의 길이와 무게 데이터를 가져와서 length와 weight에 넣는다. 그러면 두 종류의 길이와 무게가 같이 섞여있는 데이터셋을 얻을 수 있다.
3. length 데이터와 weight 데이터를 산점도에 표시하면 다음과 같다.

<img src="https://user-images.githubusercontent.com/97590480/153829318-bfa451ab-e089-460d-8e48-fd2ca01c9cdb.png">

___

#### 2. label 데이터 설정
label 데이터는 우리에게 친숙한 표현으로는 종속변수, y값과 비슷한 데이터이다. 즉, 내가 원하는 정답이 있는 데이터이다. 우리는 길이와 무게 데이터를 이용해서 이 데이터가 도미를 의미하는지, 아니면 빙어를 의미하는지 분류하고 그 데이터가 도미라면 label값을 1로, 빙어라면 label값을 0으로 설정해준다.

```python
fish_data = [[l,w] for l, w in zip (length, weight)]
fish_target = [1] * 35 + [0] * 14
```
1. fish_data에는 우리가 위에서 저장한 길이와 무게가 리스트 형태로 같이 묶여있다. 데이터의 총 갯수는 49개이다.
2. fish_target은 위에서 묶은 데이터에 따라 이 묶음 데이터는 도미를, 다른 묶음 데이터는 빙어를 의미하는지 표시해주는 데이터이다.
3. 예를들어, fish_data가 (25.4, 242.0)이라면 크기와 무게가 큰 도미의 데이터이므로 label값을 1로 설정해준다. ~다른 숫자로 설정해줘도 상관없다.~ 반면에, fish_data가 (9.8, 6.7)이라면 크기와 무게가 작은 빙어의 데이터이므로 label값을 0으로 설정해준다.
4. 즉 우리는 label데이터로 이게 도미인지 빙어인지 구분할 수 있게 됐다.

___

#### 3. KNN
여기서 우리는 KNN을 사용할 것이다. K-Nearest Neighbors 분류법(KNN)은 한 변수에서 가장 근접한 K개의 데이터들에 포함되는 범주로 분류하는 방법을 말한다. 대표적인 지도학습(supervised learning)으로, 그 중에서도 분류에 속하는 알고리즘이다. 특히 KNN은 훈련이 필요가 없기 때문에 우리가 위에서 봤던 데이터들을 어떤 훈련없이 그대로 사용한다. 그래서 KNN을 lazy model이라고도 한다.

<img src="https://user-images.githubusercontent.com/97590480/153855977-cafd1765-8e25-4c60-bd0c-41b86f8f8d5c.png">

> KNN을 잘 설명해주는 그림이다.
1. 여기서 빨간색 점이 나의 관심 대상 데이터라고 보면, 빨간색 점 주위로 가장 가까운 데이터를 찾는다.
2. 만약, K=3이라면 3개의 변수들을 찾기 때문에, 노랑 1개, 보라 2개로 빨간점을 설명할 수 있다. 그 중에서 보라색의 비중이 더 많기 때문에 빨간색 점은 보라색인 class B에 속한다고 판단할 수 있다.
3. 만약, K=6이라면 노랑이 4개, 보라가 2개로 노란색이 더 많기 때문에 빨간점은 class A에 속한다고 판단할 수 있다.
4. 이런 식으로 거리가 가장 가까운 순으로 대상의 속성을 판단하고 분류한다.

```python
kn49 = KNeighborsClassifier()   # n_neighbors = 5 default
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)
```
1. `KNeighborsClassifier()`을 사용해서 KNN을 불러온다. 여기서 n_neighbors는 위에서 K를 의미한다. 아무것도 입력하지 않을 경우 K = 5로 설정된다.
2. `.fit(fish_data, fish_target)`은 훈련을 시키는 명령어이다. `fish_data`가 입력변수, `fish_target`이 label이라는 것을 알려주기 위한 매서드이다. 그러나 KNN은 어떠한 훈련이 필요가 없으므로 변수가 그대로인 상태를 유지한다.
3. `.score(fish_data, fish_target)`은 테스트를 시키는 명령어이다. 즉, 여기서 내가 어떤 변수를 넣었을 경우 K = 5인 바운더리 안에서 분류가 정확하게 이루어지는지 확인해주는 명령어이다.
    - 여기서 값이 1이 나오는데 1은 100% 맞다는 의미한다.
    - 위에 산점도를 봐도 알수 있듯이 각 데이터들이 멀리 떨어져있고, 어떤 점을 찍어도 가장 가까운 변수들 중에서 5개를 골라도 도미를 빙어로, 빙어를 도미로 잘못 판단하는 경우는 전혀 없다는 것이다.
    - 반대로 K의 값이 커짐에 따라 빙어를 도미로 잘못 판단할 가능성이 높아진다. 빙어보다 도미의 갯수가 더 많기 때문에 위의 그림처럼 처음엔 예측을 잘 하더라도 갯수가 더 많은 그룹으로 오인할 가능성이 높아진다. **그렇기 때문에 K의 수를 어떻게 설정할 것인가가 KNN의 핵심이다**
___

### 4. KNN K=49
위에서는 K = 5일때의 KNN을 알아보았다. 이번에는 KNN이 전체 데이터를 포함하는 K = 49일때에 어떻게 변하는지 보자.

```python
kn49 = KNeighborsClassifier(n_neighbors=49)
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)
```
1. 위 코드를 실행하면 .score 결과값이 0.7142...값이 나온다. 이는 35/49를 계산했을때 동일하게 나온다. 즉, 어떤 변수를 설정해도 가장 갯수가 많은 도미로 분류가 된다.
2. fish_data 중에서 빙어의 갯수는 14개이므로 49중에서 도미인 것들의 비중은 35/49이므로 정확도는 35/49이다.
3. 즉 전체 데이터 중에서 KNN을 실행할 경우 전체 데이터는 도미로 분류되고, 도미로 분류되었는데 실제로는 빙어인 값들은 우리가 잘못 판단했으므로 정확도가 그만큼 떨어지기 때문에 score값이 35/49이 된다.
___

### 5. training과 test분류
위에처럼 모든 데이터를 넣을 경우 정확도가 떨어질 수 있기 때문에 그중에 일부를 테스트 데이터로 남겨두고 트레이닝 데이터로 모델을 만든 다음에 테스트 데이터로 정확도를 평가한다. 예를 보자

```python
train_input = fish_data[:35]
train_target = fish_target[:35]
test_input = fish_data[35:]
test_target = fish_target[35:]
kn = kn.fit(train_input, train_target)
kn.score(test_input, test_target)
```
1. 위의 코드는 35개의 도미 데이터를 훈련용 데이터로, 빙어의 데이터를 테스트용 데이터로 설정한 코드이다.
2. 그러나 도미와 빙어는 서로 다른 label값을 갖는다. 아무리 빙어로 도미인지 아닌지 구별해봐도 결과는 다르다는 결과인 0밖에 나오지 않는다.
3. 즉, 테스트용 데이터는 적절히 도미와 빙어를 섞어서 전체 데이터의 특징을 잘 반영해야 한다.

___

### 6. 랜덤값 설정
```python
np.random.seed(42)
index = np.arange(49)
np.random.shuffle(index)
```
1. 우리는 위에서 numpy를 불러왔다. 여기서 `np.random.seed(42)`는 랜덤한 고정값을 추출하는 것을 의미한다.
   - 이게 무슨 의미냐면 랜덤한 값을 설정할 경우 내 컴퓨터에서는 괜찮지만 다른 사람 컴퓨터로 코드를 넘겼을 경우 서로 다른 값때문에 해석에 오류가 발생할 수 있다.
   - 이러한 것을 방지하기 위해 랜덤한 값을 뽑고 그 값을 고정해준다. seed(42)값을 설정하면 seed(42)를 설정한 전세계 모든 사람들은 동일한 값들을 가진다.
2. `np.arange(49)`로 0부터 48까지의 숫자들을 리스트 안에 넣어준다.
3. `np.random.shuffle()`을 이용해서 위의 49개의 값들을 랜덤하게 섞어준다. 이때 seed(42)로 인해 다른 사람도 동일한 값이 나온다.

<img src="https://user-images.githubusercontent.com/97590480/153862461-72eb687c-8b6f-45b8-99e3-55be137bc191.png">

> 이렇게 나온다.

___

### 7. 랜덤값을 이용한 인덱싱으로 섞어주기
```python
input_arr = np.array(fish_data)
target_arr = np.array(fish_target)
test_input = input_arr[index[35:]]
test_target = target_arr[index[35:]]

plt.scatter(train_input[:,0], train_input[:,1])
plt.scatter(test_input[:,0], test_input[:,1])
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
위의 코드를 실행하고 산점도를 도출하면 다음과 같다.

<img src="https://user-images.githubusercontent.com/97590480/153862853-c2ae7539-700d-4f33-a360-77586760c2cd.png">

> 적절히 잘 섞인 것을 확인할 수 있다.

이를 이용해 K = 5 인 KNN을 평가해보면 잘 나오는 것을 볼 수 있다.

```python
kn = kn.fit(train_input, train_target)
print(kn.predict(test_input))
print(test_target)
kn.score(test_input, test_target)
```
위의 코드를 실행하면 다음과 같이 나온다.

<img src="https://user-images.githubusercontent.com/97590480/153863255-a25aec90-f9a5-48b9-a546-249fe1d310b1.png">

1. `kn.predict(test_input)`은 test_input의 label값을 리스트 형태로 받는다. 즉, `kn.fit()`으로 훈련시킨 데이터 모델을 test_input 데이터로 넣었을 때 제대로 잘 분류하는지를 label값으로 말해준다.
2. 여기서 k=5인 KNN을 훈련시켰으므로 test_input안에 들어있는 각각의 데이터를 변수로 설정하고 이 변수와 가장 가까운 데이터의 갯수로 그룹을 분류하여 변수가 도미로 분류된다면 1로, 빙어로 분류된다면 0으로 값을 받을 것이다. 그러한 값들이 모여 하나의 리스트로 저장된다.
3. `test_target`은 실제 참값이므로 위에서 test_input을 KNN 모델을 이용해서 label로 변경해줬을 경우 실제 label값인 test_target과 일치하는 비중이 얼마나 되는지 `.score` 매서드를 이용해서 알려준다.
4. 여기서는 정확도가 1이 나오므로 K=5로 설정한 KNN 모델이 적절한 모델이였음을 확인할 수 있다.